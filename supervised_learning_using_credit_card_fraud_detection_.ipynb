{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIsZoDNdQnCA",
        "outputId": "ef2dfc88-e661-4ddc-bddf-fbd9c4d9c697",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "train_df = pd.read_csv(\"fraudTrain.csv\")\n",
        "test_df  = pd.read_csv(\"fraudTest.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# BASIC CLEANUP\n",
        "# -----------------------------\n",
        "DROP_COLS = [\"Unnamed: 0\", \"trans_num\"]\n",
        "\n",
        "for col in DROP_COLS:\n",
        "    if col in train_df.columns:\n",
        "        train_df.drop(columns=col, inplace=True)\n",
        "    if col in test_df.columns:\n",
        "        test_df.drop(columns=col, inplace=True)\n",
        "\n",
        "# -----------------------------\n",
        "# TARGET / FEATURES\n",
        "# -----------------------------\n",
        "TARGET = \"is_fraud\"\n",
        "assert TARGET in train_df.columns, \"Target column missing\"\n",
        "\n",
        "# Drop rows where the target variable is NaN in the training set\n",
        "train_df.dropna(subset=[TARGET], inplace=True)\n",
        "\n",
        "X = train_df.drop(TARGET, axis=1)\n",
        "y = train_df[TARGET]\n",
        "\n",
        "# -----------------------------\n",
        "# COLUMN TYPES\n",
        "# -----------------------------\n",
        "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "numerical_cols   = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "\n",
        "# -----------------------------\n",
        "# PREPROCESSOR (SPARSE!)\n",
        "# -----------------------------\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_cols),\n",
        "        (\n",
        "            \"cat\",\n",
        "            OneHotEncoder(\n",
        "                handle_unknown=\"ignore\",\n",
        "                sparse_output=True,        # CRITICAL: Changed 'sparse' to 'sparse_output'\n",
        "                dtype=np.float32    # reduce memory further\n",
        "            ),\n",
        "            categorical_cols\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# MODEL (SPARSE-SAFE)\n",
        "# -----------------------------\n",
        "model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight=\"balanced\",\n",
        "    solver=\"saga\",   # REQUIRED for sparse + large data\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# PIPELINE\n",
        "# -----------------------------\n",
        "pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", model)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# TRAIN / VALIDATION SPLIT\n",
        "# -----------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# TRAIN\n",
        "# -----------------------------\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# EVALUATION\n",
        "# -----------------------------\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "print(\"\\nCLASSIFICATION REPORT\\n\")\n",
        "print(classification_report(y_val, y_pred, digits=4))\n",
        "\n",
        "print(\"\\nCONFUSION MATRIX\\n\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# TEST SET PREDICTIONS\n",
        "# -----------------------------\n",
        "# Drop rows with NaN values from test_df before prediction\n",
        "test_df.dropna(inplace=True)\n",
        "test_preds = pipeline.predict(test_df)\n",
        "test_df[\"predicted_fraud\"] = test_preds\n",
        "test_df.to_csv(\"fraud_predictions.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved: fraud_predictions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOGWVJ7cTZYi",
        "outputId": "1eb9849c-6fb5-4ec8-ef40-2684da695802"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLASSIFICATION REPORT\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9986    0.9812    0.9898     14644\n",
            "         1.0     0.3056    0.8582    0.4507       141\n",
            "\n",
            "    accuracy                         0.9800     14785\n",
            "   macro avg     0.6521    0.9197    0.7202     14785\n",
            "weighted avg     0.9920    0.9800    0.9847     14785\n",
            "\n",
            "\n",
            "CONFUSION MATRIX\n",
            "\n",
            "[[14369   275]\n",
            " [   20   121]]\n",
            "\n",
            "Saved: fraud_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}